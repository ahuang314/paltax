{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c25b11e-67a9-4214-8157-14442d4489bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.visualization import simple_norm\n",
    "import corner\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from matplotlib.patches import ConnectionPatch, FancyBboxPatch, Ellipse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats, signal\n",
    "\n",
    "from paltax import input_pipeline\n",
    "from paltax import train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027d851e-033a-43b6-8718-b12e21b3a6bf",
   "metadata": {},
   "source": [
    "# Reproduce the paper Figures\n",
    "__To generate all of the figures in this notebook, you will have to download figure_data.zip from [TODO](https://google.com) and expand it into this folder.__\n",
    "\n",
    "This notebook is built to work with `paltax` version `1.0.0`. Later versions __may not work__ with this code.\n",
    "\n",
    "Figures:\n",
    "- [Figure 1](#figure_1)\n",
    "- [Figure 2](#figure_2)\n",
    "- [Figure 3](#figure_3)\n",
    "- [Figure 4](#figure_4)\n",
    "- [Figure_5](#figure_5)\n",
    "- [Figure 6](#figure_6)\n",
    "- [Figure 7](#figure_7)\n",
    "- [Figure 8](#figure_8)\n",
    "- [Figure 9](#figure_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee2db03-70ad-4b55-9417-f4bd2c09ce9d",
   "metadata": {},
   "source": [
    "## Figure 1 <a id='figure_1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c125a09b-eef7-4b1a-8c8f-a78b62c76d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data we need for the figures\n",
    "mock_index = 5\n",
    "image_hier = np.load('figure_data/image_hier.npy')\n",
    "image_draws_list = np.load('figure_data/image_draws_list_5.npy')\n",
    "def create_flexible_grid(images, n_row, n_col):\n",
    "    placeholder = images[:n_row * n_col].reshape((n_row, n_col, *images.shape[1:]))\n",
    "    return np.vstack([np.hstack(image) for image in placeholder])\n",
    "    \n",
    "# Create the tableau on which we will add our plots.\n",
    "figsize = (16,10)\n",
    "fig = plt.figure(figsize=figsize, dpi=100)\n",
    "fontsize = 15\n",
    "spine_width = 2\n",
    "method_colors = ['#d95f02', '#1b9e77']\n",
    "\n",
    "# Use the image mock to set the normalization for images that will be drawn.\n",
    "image_mock = image_hier[mock_index] * np.mean(np.std(image_draws_list[0].reshape(image_draws_list[0].shape[0],-1), axis=1))\n",
    "im_norm = simple_norm(image_mock,stretch='asinh')\n",
    "    \n",
    "# Add the samples from the prior distribution.\n",
    "image_box_size = 0.08\n",
    "n_row = 2\n",
    "n_col = 3\n",
    "prior_samples_ax = fig.add_axes([0.1, 0.7, figsize[1]/figsize[0]*image_box_size*n_col, image_box_size*n_row])\n",
    "prior_samples_ax.imshow(create_flexible_grid(image_draws_list[0], n_row, n_col), norm=im_norm, cmap='plasma')\n",
    "prior_samples_ax.get_xaxis().set_visible(False)\n",
    "prior_samples_ax.get_yaxis().set_visible(False)\n",
    "prior_samples_ax.text(128*n_col/2, -20, \n",
    "                      r'Draw from $\\theta_n \\sim p(\\theta|\\Omega_0)$,' + '\\n' + r'Simulate $x_n \\sim g(x|\\theta_n)$',\n",
    "                      fontsize=fontsize, ha='center', color='black')\n",
    "\n",
    "# Add the samples from the sequential proposal distribution.\n",
    "seq_samples_ax = fig.add_axes([0.30 + figsize[1]/figsize[0]*image_box_size*1.5, 0.40, \n",
    "                               figsize[1]/figsize[0]*image_box_size*n_col , image_box_size*n_row])\n",
    "seq_samples_ax.imshow(create_flexible_grid(image_draws_list[1], n_row, n_col), norm=im_norm, cmap='plasma')\n",
    "seq_samples_ax.get_xaxis().set_visible(False)\n",
    "seq_samples_ax.get_yaxis().set_visible(False)\n",
    "seq_samples_ax.text(128*n_col/2, -20, \n",
    "                    r'Draw from $\\theta_n \\sim p(\\theta|\\Omega_i)$,' + '\\n' + r'Simulate $x_n \\sim g(x|\\theta_n)$', \n",
    "                    fontsize=fontsize, ha='center', color='black')\n",
    "\n",
    "# Add initial prior distribution\n",
    "prior_dist_ax = fig.add_axes([-0.04, 0.7, figsize[1]/figsize[0]*image_box_size*2, image_box_size*2])\n",
    "prior_dist_ax.get_xaxis().set_visible(False)\n",
    "prior_dist_ax.get_yaxis().set_visible(False)\n",
    "for spine in prior_dist_ax.spines.values():\n",
    "    spine.set_linewidth(spine_width)\n",
    "prior_dist_ax.text(0.5, 1.0 + 20/256, r'Specify prior', fontsize=fontsize, ha='center', color='black')\n",
    "prior_dist_ax.text(0.5, 0.85, r'$p(\\theta|\\Omega_0)$', fontsize=fontsize, ha='center', color='black')\n",
    "prior_dist = fig.add_axes([-0.04 + figsize[1]/figsize[0]*image_box_size*0.4, 0.72, figsize[1]/figsize[0]*image_box_size*1.2, image_box_size*1.2])\n",
    "ellipse = Ellipse(xy=(1.0, 1.0), width=1.5, height=1.5, angle=0, edgecolor='none', facecolor='grey')\n",
    "prior_dist.add_patch(ellipse)\n",
    "prior_dist.set_xlim([-0.1,2.1])\n",
    "prior_dist.set_ylim([-0.1,2.1])\n",
    "prior_dist.set_yticks([])\n",
    "prior_dist.set_xticks([])\n",
    "prior_dist.spines['top'].set_visible(False)\n",
    "prior_dist.spines['right'].set_visible(False)\n",
    "\n",
    "# Add the two types of loss function.\n",
    "loss_ax = fig.add_axes([0.29, 0.7, figsize[1]/figsize[0]*image_box_size*5 , image_box_size*2])\n",
    "loss_ax.text(0.5, 1.0 + 20/256, r'Train model to predict posterior:' + '\\n' + r'$q_{\\phi}(\\theta|x,\\Omega_0) \\ \\to \\ p(\\theta|x,\\Omega_0)$', fontsize=fontsize, ha='center', color='black')\n",
    "loss_ax.get_xaxis().set_visible(False)\n",
    "loss_ax.get_yaxis().set_visible(False)\n",
    "loss_ax.axhline(0.5, 0.1, 0.9, c='k')\n",
    "loss_ax.text(0.5, 0.75, \n",
    "             r'NPE: $\\mathcal{L}(\\phi) = - \\sum \\log q_\\phi$',\n",
    "             fontsize=fontsize*0.9, ha='center', va='center', color=method_colors[0])\n",
    "loss_ax.text(0.5, 0.25, \n",
    "             r'SNPE: $\\mathcal{L}(\\phi) = - \\sum \\log \\left[ q_\\phi \\times \\mathrm{Reweighting} \\right]$', \n",
    "             fontsize=fontsize*0.9, ha='center', va='center', color=method_colors[1])\n",
    "for spine in loss_ax.spines.values():\n",
    "    spine.set_linewidth(spine_width)\n",
    "    \n",
    "# Add the prediction on the observed image\n",
    "pred_img_ax = fig.add_axes([0.58, 0.7, figsize[1]/figsize[0]*image_box_size*5.5, image_box_size*2])\n",
    "pred_img_ax.get_xaxis().set_visible(False)\n",
    "pred_img_ax.get_yaxis().set_visible(False)\n",
    "pred_img_ax.text(0.5, 1.0 + 20/256, 'Predict posterior on \\n' + r'observed image $x_\\mathrm{obs}$', fontsize=fontsize, ha='center', color='black')\n",
    "for spine in pred_img_ax.spines.values():\n",
    "    spine.set_linewidth(spine_width)\n",
    "# Add the observed image\n",
    "obs_img_ax = fig.add_axes([0.59, 0.7 + image_box_size*0.25, figsize[1]/figsize[0]*image_box_size*1.5, image_box_size*1.5])\n",
    "obs_img_ax.imshow(image_mock, norm=im_norm, cmap='plasma')\n",
    "obs_img_ax.get_xaxis().set_visible(False)\n",
    "obs_img_ax.get_yaxis().set_visible(False)\n",
    "# Add the model\n",
    "model_ax = fig.add_axes([0.695, 0.7 + image_box_size*0.5, figsize[1]/figsize[0]*image_box_size, image_box_size],\n",
    "                        facecolor='grey')\n",
    "model_ax.get_xaxis().set_visible(False)\n",
    "model_ax.get_yaxis().set_visible(False)\n",
    "model_ax.text(0.5, 0.5, 'Trained\\nModel',\n",
    "              fontsize=fontsize, ha='center', va='center', color='white')\n",
    "#Add the prediction\n",
    "pred_img_ax.text(0.835, 0.85, r'$q_{\\phi}(\\theta|x_\\mathrm{obs},\\Omega_0)$', fontsize=fontsize*0.9, ha='center', va='center', color='k')\n",
    "pred_q = fig.add_axes([0.782, 0.72, figsize[1]/figsize[0]*image_box_size*1.2, image_box_size*1.2])\n",
    "ellipse = Ellipse(xy=(0.9, 1.2), width=0.7, height=1.2, angle=30, edgecolor='none', facecolor='k')\n",
    "pred_q.add_patch(ellipse)\n",
    "pred_q.set_xlim([-0.1,2.1])\n",
    "pred_q.set_ylim([-0.1,2.1])\n",
    "pred_q.set_yticks([])\n",
    "pred_q.set_xticks([])\n",
    "pred_q.spines['top'].set_visible(False)\n",
    "pred_q.spines['right'].set_visible(False)\n",
    "\n",
    "# Add the sequential proposal stage\n",
    "seq_prop_ax = fig.add_axes([0.59, 0.40, figsize[1]/figsize[0]*image_box_size*3.5, image_box_size*2])\n",
    "seq_prop_ax.get_xaxis().set_visible(False)\n",
    "seq_prop_ax.get_yaxis().set_visible(False)\n",
    "seq_prop_ax.text(0.5, 1.0 + 20/256, 'Generate new proposal\\n' + r'distribution: $p(\\theta | \\Omega_i)$', fontsize=fontsize, ha='center', color='black')\n",
    "for spine in seq_prop_ax.spines.values():\n",
    "    spine.set_linewidth(spine_width)\n",
    "# Add the proposal transition\n",
    "snpe_dist_axes = []\n",
    "for x_coord, y_coord, color in zip(\n",
    "    [0.59 + figsize[1]/figsize[0]*image_box_size*2.05, 0.59 + figsize[1]/figsize[0]*image_box_size*0.25],\n",
    "    [0.42, 0.42], ['k', 'grey']):\n",
    "    pred_q = fig.add_axes([x_coord, y_coord, figsize[1]/figsize[0]*image_box_size*1.2, image_box_size*1.2])\n",
    "    snpe_dist_axes.append(pred_q)\n",
    "    ellipse = Ellipse(xy=(0.9, 1.2), width=0.7, height=1.2, angle=30, edgecolor='none', facecolor=color)\n",
    "    pred_q.add_patch(ellipse)\n",
    "    pred_q.set_xlim([-0.1,2.1])\n",
    "    pred_q.set_ylim([-0.1,2.1])\n",
    "    pred_q.set_yticks([])\n",
    "    pred_q.set_xticks([])\n",
    "    pred_q.spines['top'].set_visible(False)\n",
    "    pred_q.spines['right'].set_visible(False)\n",
    "    \n",
    "# Set NPE boundary\n",
    "npe_bound_ax = fig.add_axes([0.08, 0.65, 0.79, 0.29], zorder=-1)\n",
    "npe_bound_ax.patch.set_alpha(0.0)\n",
    "npe_bound_ax.get_xaxis().set_visible(False)\n",
    "npe_bound_ax.get_yaxis().set_visible(False)\n",
    "for spine in npe_bound_ax.spines.values():\n",
    "    # spine.set_linewidth(spine_width*2)\n",
    "    # spine.set_color(method_colors[0])\n",
    "    spine.set_visible(False)\n",
    "npe_bound_ax.text(0.112, 0.07, 'NPE', fontsize=fontsize*1.5, ha='center', va='center', color=method_colors[0], weight='bold')\n",
    "fill_box = FancyBboxPatch((0, 0), 1, 1,\n",
    "                        boxstyle=\"round,pad=-0.0040,rounding_size=0.1\",\n",
    "                        ec='white', fc='white', clip_on=False, lw=spine_width*2,\n",
    "                        mutation_aspect=1,\n",
    "                        transform=npe_bound_ax.transAxes)\n",
    "npe_bound_ax.add_patch(fill_box)\n",
    "fill_box = FancyBboxPatch((0, 0), 1, 1,\n",
    "                        boxstyle=\"round,pad=-0.0040,rounding_size=0.1\",\n",
    "                        ec=method_colors[0], fc=method_colors[0], clip_on=False, lw=spine_width*2,\n",
    "                        mutation_aspect=1, alpha=0.15,\n",
    "                        transform=npe_bound_ax.transAxes)\n",
    "npe_bound_ax.add_patch(fill_box)\n",
    "    \n",
    "# Set SNPE boundary\n",
    "snpe_bound_ax = fig.add_axes([0.07, 0.39, 0.81, 0.57], zorder=-2)\n",
    "snpe_bound_ax.patch.set_alpha(0.0)\n",
    "snpe_bound_ax.get_xaxis().set_visible(False)\n",
    "snpe_bound_ax.get_yaxis().set_visible(False)\n",
    "for spine in snpe_bound_ax.spines.values():\n",
    "    # spine.set_linewidth(spine_width*2)\n",
    "    # spine.set_color(method_colors[1])\n",
    "    spine.set_visible(False)\n",
    "npe_bound_ax.text(0.112, -0.8, 'SNPE', fontsize=fontsize*1.5, ha='center', va='center', color=method_colors[1], weight='bold')\n",
    "fill_box = FancyBboxPatch((0, 0), 1, 1,\n",
    "                        boxstyle=\"round,pad=-0.0040,rounding_size=0.1\",\n",
    "                        ec=method_colors[1], fc=method_colors[1], clip_on=False, lw=spine_width*2,\n",
    "                        mutation_aspect=1, alpha=0.15,\n",
    "                        transform=snpe_bound_ax.transAxes)\n",
    "snpe_bound_ax.add_patch(fill_box)\n",
    "\n",
    "# Add the arrows\n",
    "arrowstyle = 'simple,head_length=1.0,head_width=2.0,tail_width=0.7'\n",
    "# Arrow from prior to prior sims\n",
    "arrow = ConnectionPatch((1 + 0.02*6/2,0.5), (-0.02*6/4,0.5), coordsA='axes fraction', coordsB='axes fraction',\n",
    "                        axesA=prior_dist_ax, axesB=prior_samples_ax, color=method_colors[0], lw=3, arrowstyle=arrowstyle, fill=True)\n",
    "fig.add_artist(arrow)\n",
    "arrow = ConnectionPatch((1 + 0.02*6/2,0.5), (-0.02*6/4,0.5), coordsA='axes fraction', coordsB='axes fraction',\n",
    "                        axesA=prior_dist_ax, axesB=prior_samples_ax, color=method_colors[1], lw=3, arrowstyle=arrowstyle, fill=False)\n",
    "fig.add_artist(arrow)\n",
    "# Arrow from prior sims to loss box\n",
    "arrow = ConnectionPatch((1 + 0.02*6/4,0.5), (-0.02,0.5), coordsA='axes fraction', coordsB='axes fraction',\n",
    "                        axesA=prior_samples_ax, axesB=loss_ax, color=method_colors[0], lw=3, arrowstyle=arrowstyle, fill=True)\n",
    "fig.add_artist(arrow)\n",
    "arrow = ConnectionPatch((1 + 0.02*6/4,0.5), (-0.02,0.5), coordsA='axes fraction', coordsB='axes fraction',\n",
    "                        axesA=prior_samples_ax, axesB=loss_ax, color=method_colors[1], lw=3, arrowstyle=arrowstyle, fill=False)\n",
    "fig.add_artist(arrow)\n",
    "# Arrow from loss box to predicted posterior\n",
    "arrow = ConnectionPatch((1.02,0.5), (-0.02 * 6/5.5,0.5), coordsA='axes fraction', coordsB='axes fraction',\n",
    "                        axesA=loss_ax, axesB=pred_img_ax, color=method_colors[0], lw=3, arrowstyle=arrowstyle, fill=True)\n",
    "fig.add_artist(arrow)\n",
    "arrow = ConnectionPatch((1.02,0.5), (-0.02 * 6/5.5,0.5), coordsA='axes fraction', coordsB='axes fraction',\n",
    "                        axesA=loss_ax, axesB=pred_img_ax, color=method_colors[1], lw=3, arrowstyle=arrowstyle, fill=False)\n",
    "fig.add_artist(arrow)\n",
    "# Arrow from predicted posterior to sequential proposal.\n",
    "connectionstyle = 'angle3,angleA=-90,angleB=0'\n",
    "arrow = ConnectionPatch((0.90,-0.05), (1.05,0.5), coordsA='axes fraction', coordsB='axes fraction',\n",
    "                        axesA=pred_img_ax, axesB=seq_prop_ax, color=method_colors[1], lw=2, arrowstyle=arrowstyle, connectionstyle=connectionstyle, fill=True)\n",
    "fig.add_artist(arrow)\n",
    "# Add arrow from sequential proposal to sequential samples.\n",
    "arrow = ConnectionPatch((-0.04,0.5), (1.05,0.5), coordsA='axes fraction', coordsB='axes fraction',\n",
    "                        axesA=seq_prop_ax, axesB=seq_samples_ax, color=method_colors[1], lw=2, arrowstyle=arrowstyle, fill=True)\n",
    "fig.add_artist(arrow)\n",
    "# Arrow from predicted posterior to sequential proposal.\n",
    "connectionstyle = 'angle3,angleA=0,angleB=90'\n",
    "arrow = ConnectionPatch((-0.04,0.5), (0.12,-0.05), coordsA='axes fraction', coordsB='axes fraction',\n",
    "                        axesA=seq_samples_ax, axesB=loss_ax, color=method_colors[1], lw=3, arrowstyle=arrowstyle, connectionstyle=connectionstyle, fill=True)\n",
    "fig.add_artist(arrow)\n",
    "# Arrow from observed image to trained model.\n",
    "arrowstyle = 'simple,head_length=0.5,head_width=0.8,tail_width=0.2'\n",
    "arrow = ConnectionPatch((1.1,0.5), (-0.15,0.5), coordsA='axes fraction', coordsB='axes fraction',\n",
    "                        axesA=obs_img_ax, axesB=model_ax, color='k', lw=2, arrowstyle=arrowstyle)\n",
    "fig.add_artist(arrow)\n",
    "# Arrow from trained model to posterior.\n",
    "arrow = ConnectionPatch((1.15,0.5), (1.55,0.5), coordsA='axes fraction', coordsB='axes fraction',\n",
    "                        axesA=model_ax, axesB=model_ax, color='k', lw=2, arrowstyle=arrowstyle)\n",
    "fig.add_artist(arrow)\n",
    "# Arrow from posterior to proposal.\n",
    "arrow = ConnectionPatch((-0.15,0.5), (1.05,0.5), coordsA='axes fraction', coordsB='axes fraction',\n",
    "                        axesA=snpe_dist_axes[0], axesB=snpe_dist_axes[1], color='k', lw=2, arrowstyle=arrowstyle)\n",
    "fig.add_artist(arrow)\n",
    "\n",
    "seq_prop_ax.text(0.25, 0.85, r'$p(\\theta | \\Omega_i)$', \n",
    "                 fontsize=fontsize*0.9, ha='center', va='center', color='black')\n",
    "seq_prop_ax.text(0.75, 0.85, r'$q_{\\phi}(\\theta|x_\\mathrm{obs}, \\Omega_{0})$', \n",
    "                 fontsize=fontsize*0.9, ha='center', va='center', color='k')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e005bb-dcbc-4f7e-a812-591a1cb487b3",
   "metadata": {},
   "source": [
    "## Figure 2 <a id='figure_2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e861c09-657f-4655-b808-66ba74da1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lopad and seperate the data.\n",
    "from paltax.TrainConfigs import train_config_npe_base\n",
    "config = train_config_npe_base.get_config()\n",
    "n_gpus_train = 4 #Number of gpus that were used in parallel when training the models.\n",
    "\n",
    "save_metrics = np.load('figure_data/npe_comparison_metrics.npy', allow_pickle=True).item()\n",
    "steps = np.arange(1, 501) * config.steps_per_epoch\n",
    "rmse_metrics = save_metrics['rmse_metrics']\n",
    "rho_metrics = save_metrics['rho_metrics']\n",
    "loss_metrics = save_metrics['loss_metrics']\n",
    "loss_ss_metrics = save_metrics['loss_ss_metrics']\n",
    "\n",
    "# Plot the loss as a function of the number of images in the dataset.\n",
    "fontsize = 15\n",
    "\n",
    "models_to_plot = ['Fiducial' , '50k', '500k', '5M']\n",
    "model_names = [r'Fiducial (Infinite Unique Images)', r'$5 \\times 10^{4}$ Unique Images', \n",
    "               r'$5 \\times 10^{5}$ Unique Images', r'$5 \\times 10^{6}$ Unique Images']\n",
    "line_styles = ['.-', '.-', '.-', '.-']\n",
    "colors = ['#969696','#cbc9e2', '#9e9ac8', '#6a51a3']\n",
    "step_scaling = [1.0] * len(models_to_plot)\n",
    "total_images = [jnp.max(steps) * config.batch_size, 5e4, 5e5, 5e6]\n",
    "    \n",
    "fig, ax = plt.subplots(1, 2, figsize=(18,8), sharey=True, gridspec_kw={'hspace': 0.02,'wspace':0.04},dpi=100)\n",
    "\n",
    "filter_size = 5\n",
    "\n",
    "for model_index, model_key in enumerate(models_to_plot):\n",
    "    loss_array = jnp.array(jax.tree_util.tree_leaves(loss_ss_metrics[model_key]))\n",
    "    loss_array = signal.medfilt(loss_array, kernel_size=filter_size)\n",
    "    ax[0].plot(steps[:len(loss_array)] * config.batch_size * n_gpus_train, loss_array, line_styles[model_index], \n",
    "               c=colors[model_index], lw=5, ms = 10, alpha=0.9)\n",
    "    if model_index > 0:\n",
    "        ax[1].plot(steps[:len(loss_array)] * config.batch_size * n_gpus_train / total_images[model_index], loss_array, '.-', \n",
    "                   c=colors[model_index], lw=5, ms = 10, alpha=0.9)\n",
    "\n",
    "ax[0].legend(model_names, fontsize=fontsize)\n",
    "ax[0].set_ylabel(r'Mean Loss on $\\Sigma_\\mathrm{sub}$', fontsize=fontsize)\n",
    "ax[0].set_xlabel('Images Seen', fontsize=fontsize)\n",
    "ax[0].set_xscale('log')\n",
    "ax[1].set_xlabel('Passes Through Dataset', fontsize=fontsize)\n",
    "ax[1].set_xscale('log')\n",
    "for axis in ax:\n",
    "    axis.tick_params(axis='both', which='both', labelsize=fontsize, length=fontsize/2, width=1.5)\n",
    "    axis.set_ylim([0.42,0.65])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d570d8-08d1-4aab-8038-7da3aeceaed0",
   "metadata": {},
   "source": [
    "## Figure 3 <a id='figure_3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4e3792-80b0-49d3-83e6-19acebc2e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lopad and seperate the data.\n",
    "from paltax.TrainConfigs import train_config_npe_base\n",
    "config = train_config_npe_base.get_config()\n",
    "n_gpus_train = 4 #Number of gpus that were used in parallel when training the models.\n",
    "\n",
    "save_metrics = np.load('figure_data/npe_comparison_metrics.npy', allow_pickle=True).item()\n",
    "steps = np.arange(1, 501) * config.steps_per_epoch\n",
    "rmse_metrics = save_metrics['rmse_metrics']\n",
    "rho_metrics = save_metrics['rho_metrics']\n",
    "loss_metrics = save_metrics['loss_metrics']\n",
    "loss_ss_metrics = save_metrics['loss_ss_metrics']\n",
    "\n",
    "from paltax.TrainConfigs import train_config_exp_fast\n",
    "from paltax.TrainConfigs import train_config_exp_slow\n",
    "from paltax.TrainConfigs import train_config_linear\n",
    "from paltax.TrainConfigs import train_config_linear_0p001\n",
    "from paltax.TrainConfigs import train_config_constant\n",
    "\n",
    "fontsize = 15\n",
    "models_to_plot = ['Fiducial', 'Exponential Slow', 'Exponential Fast', 'Constant', 'Linear', 'Linear Small Base']\n",
    "model_names = ['Fiducial (Warmup + Cosine Decay)', 'Exponential Decay: 0.99', 'Exponential Decay: 0.98', \n",
    "               r'Constant Learning Rate', r'Linear Decay, Learning Rate: $10^{-2}$', r'Linear Decay, Learning Rate: $10^{-3}$']\n",
    "learning_rate_schedule = train.get_learning_rate_schedule(config, config.learning_rate)\n",
    "lr_exp_fast = train.get_learning_rate_schedule(train_config_exp_fast.get_config(), config.learning_rate)\n",
    "lr_exp_slow = train.get_learning_rate_schedule(train_config_exp_slow.get_config(), config.learning_rate)\n",
    "lr_lin_01 = train.get_learning_rate_schedule(train_config_linear.get_config(), config.learning_rate)\n",
    "lr_lin_001 = train.get_learning_rate_schedule(train_config_linear.get_config(), train_config_linear_0p001.get_config().learning_rate)\n",
    "lr_const = train.get_learning_rate_schedule(train_config_constant.get_config(), config.learning_rate)\n",
    "learning_rate_schedule_list = [learning_rate_schedule, lr_exp_slow, lr_exp_fast, lr_const, lr_lin_01, lr_lin_001]\n",
    "colors = ['#969696', '#fdd0a2', '#fdae6b', '#fd8d3c', '#e6550d', '#a63603']\n",
    "line_styles = ['.-', '.-', '.-', '.-', '.-', '.-', '.-']\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18,8), sharey=True, gridspec_kw={'hspace': 0.02,'wspace':0.04},dpi=100)\n",
    "\n",
    "filter_size = 5\n",
    "\n",
    "for model_index, model_key in enumerate(models_to_plot):\n",
    "    loss_array = jnp.array(jax.tree_util.tree_leaves(loss_ss_metrics[model_key]))\n",
    "    loss_array = signal.medfilt(loss_array, kernel_size=filter_size)\n",
    "    ax[0].plot(steps[:len(loss_array)] * config.batch_size * n_gpus_train, loss_array, line_styles[model_index],\n",
    "               c=colors[model_index], lw=3, ms = 10, alpha=0.9)\n",
    "    schedule = learning_rate_schedule_list[model_index]\n",
    "    ax[1].plot(schedule(steps[:len(loss_array)])* config.batch_size / 256, loss_array, '.-', \n",
    "               c=colors[model_index], lw=3, ms = 10, alpha=0.9)\n",
    "\n",
    "ax[0].legend(model_names, fontsize=fontsize)\n",
    "ax[0].set_ylabel(r'Mean Loss on $\\Sigma_\\mathrm{sub}$', fontsize=fontsize)\n",
    "ax[0].set_xlabel('Images Seen', fontsize=fontsize)\n",
    "ax[1].set_xlabel('Learning Rate', fontsize=fontsize)\n",
    "ax[1].invert_xaxis()\n",
    "ax[0].set_xscale('log')\n",
    "for axis in ax:\n",
    "    axis.tick_params(axis='both', which='both', labelsize=fontsize, length=fontsize/2, width=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae52a9e1-93f8-4c9b-86da-3e2ad745791a",
   "metadata": {},
   "source": [
    "## Figure 4 <a id='figure_4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed5d2be-f4c1-43bb-9db7-6ac16c522e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lopad and seperate the data.\n",
    "from paltax.TrainConfigs import train_config_npe_base\n",
    "config = train_config_npe_base.get_config()\n",
    "n_gpus_train = 4 #Number of gpus that were used in parallel when training the models.\n",
    "\n",
    "save_metrics = np.load('figure_data/npe_comparison_metrics.npy', allow_pickle=True).item()\n",
    "steps = np.arange(1, 501) * config.steps_per_epoch\n",
    "rmse_metrics = save_metrics['rmse_metrics']\n",
    "rho_metrics = save_metrics['rho_metrics']\n",
    "loss_metrics = save_metrics['loss_metrics']\n",
    "loss_ss_metrics = save_metrics['loss_ss_metrics']\n",
    "\n",
    "fontsize = 15\n",
    "\n",
    "models_to_plot = ['Fiducial', 'Resnet 18 Very Small', 'Resnet 18 Small', 'Resnet 18', 'Resnet 34', 'Resnet-D 50']\n",
    "model_names = ['Fiducial (Resnet 50)', 'Resnet 18 Very Small', 'Resnet 18 Small', 'Resnet 18', 'Resnet 34', 'Resnet-D 50']\n",
    "colors = ['#969696', '#c6dbef', '#9ecae1', '#6baed6', '#4292c6', '#2171b5', '#084594']\n",
    "line_styles = ['.-', '.-', '.-', '.-', '.-', '.-', '.-']\n",
    "step_scaling = [1.0, 0.0303, 0.0605, 0.242, 0.355, 1.0]\n",
    "flops_50 = 5.24e8\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18,8), sharey=True, gridspec_kw={'hspace': 0.02,'wspace':0.04},dpi=100)\n",
    "\n",
    "filter_size = 5\n",
    "\n",
    "for model_index, model_key in enumerate(models_to_plot):\n",
    "    loss_array = jnp.array(jax.tree_util.tree_leaves(loss_ss_metrics[model_key]))\n",
    "    loss_array = signal.medfilt(loss_array, kernel_size=filter_size)\n",
    "    ax[0].plot(steps[:len(loss_array)] * config.batch_size * n_gpus_train, loss_array, line_styles[model_index],\n",
    "               c=colors[model_index], lw=3, ms = 10, alpha=0.9)\n",
    "    ax[1].plot(steps[:len(loss_array)] * flops_50 * step_scaling[model_index]* n_gpus_train, loss_array, \n",
    "               line_styles[model_index], c=colors[model_index], lw=3, ms = 10, alpha=0.9)\n",
    "\n",
    "ax[0].legend(model_names, fontsize=fontsize)\n",
    "ax[0].set_ylabel(r'Mean Loss on $\\Sigma_\\mathrm{sub}$', fontsize=fontsize)\n",
    "ax[0].set_xlabel('Images Seen', fontsize=fontsize)\n",
    "ax[1].set_xlabel('FLOPs', fontsize=fontsize)\n",
    "for axis in ax:\n",
    "    axis.tick_params(axis='both', which='both', labelsize=fontsize, length=fontsize/2, width=1.5)\n",
    "    axis.set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6220ad-e2e4-42c7-af60-b709f92e0f3a",
   "metadata": {},
   "source": [
    "## Figure 5 <a id='figure_5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c816d4-0079-4697-9c82-87a1d644beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the loss data\n",
    "save_metrics = np.load('figure_data/snpe_comparison_metrics.npy', allow_pickle=True).item()\n",
    "log_post_metrics = save_metrics['log_post_metrics']\n",
    "log_post_sub_metrics = save_metrics['log_post_sub_metrics']\n",
    "\n",
    "log_post_sub_array = []\n",
    "for mn in [f'Image {mod_num}' for mod_num in range(30)]:\n",
    "    log_post_sub_array += [jnp.array(jax.tree_util.tree_leaves(log_post_sub_metrics[mn]))]\n",
    "log_post_sub_array = jnp.array(log_post_sub_array)\n",
    "\n",
    "log_post_array = []\n",
    "for mn in [f'Image {mod_num}' for mod_num in range(30)]:\n",
    "    log_post_array += [jnp.array(jax.tree_util.tree_leaves(log_post_metrics[mn]))]\n",
    "log_post_array = jnp.array(log_post_array)\n",
    "\n",
    "# Pull the relevant configuration files.\n",
    "from paltax.TrainConfigs import train_config_npe_base\n",
    "from paltax.TrainConfigs import train_config_snpe_base\n",
    "config = train_config_npe_base.get_config()\n",
    "snpe_config = train_config_snpe_base.get_config()\n",
    "n_gpus_train = 4 #Number of gpus that were used in parallel when training the models.\n",
    "\n",
    "steps = np.arange(1,501) * config.steps_per_epoch\n",
    "steps_snpe = np.arange(1,50) * config.steps_per_epoch\n",
    "\n",
    "fontsize = 15\n",
    "\n",
    "colors = ['#d95f02', '#1b9e77', '#252525', 'grey']\n",
    "\n",
    "fit_cut = 50\n",
    "snpe_cut = 40\n",
    "filter_size = 5\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize=(15,8), sharey=True, gridspec_kw={'hspace': 0.02,'wspace':0.04},dpi=100)\n",
    "\n",
    "# Extract the npe / snpe results and make a linear fit to the power-law performance\n",
    "npe_loss_array = jax.tree_util.tree_leaves(log_post_sub_metrics['Fiducial'])\n",
    "lin_fit = stats.linregress(np.log10(steps[fit_cut:] * config.batch_size), npe_loss_array[fit_cut:])\n",
    "npe_loss_array = signal.medfilt(npe_loss_array, kernel_size=filter_size)\n",
    "snpe_loss_array = signal.medfilt(np.mean(log_post_sub_array[:,:snpe_cut], axis=0), kernel_size=filter_size)\n",
    "\n",
    "# Plot the npe results and the power law.\n",
    "ax.plot(steps[:len(npe_loss_array)] * config.batch_size * n_gpus_train, npe_loss_array, '.-', \n",
    "        c=colors[0], lw=3, ms = 10, alpha=0.9)\n",
    "start_step = np.log10(steps[fit_cut] * config.batch_size)\n",
    "final_step = (snpe_loss_array[-1] - lin_fit[1])/lin_fit[0]\n",
    "p_law_steps = np.linspace(start_step, final_step, 100)\n",
    "p_law = lin_fit[0]*p_law_steps + lin_fit[1]\n",
    "ax.plot(10**(p_law_steps)*n_gpus_train, p_law, '--', c=colors[2], lw=3)\n",
    "\n",
    "# Plot the snpe results\n",
    "ax.plot(steps_snpe[:snpe_cut] * config.batch_size * n_gpus_train, snpe_loss_array, '.-', c=colors[1], lw=3, ms = 10, \n",
    "        alpha=0.9)\n",
    "ax.axhspan(snpe_loss_array[-1]*0.95, snpe_loss_array[-1]*1.05, alpha=0.2, color=colors[3])\n",
    "ax.text(5.2e5,snpe_loss_array[-1]*1.018, r'Sequential Performance', color='white', fontsize=fontsize,\n",
    "        bbox=dict(boxstyle=\"round\",ec='#969696',fc='#969696'))\n",
    "\n",
    "ax.set_ylabel(r'Mean Loss on $\\Sigma_\\mathrm{sub}$', fontsize=fontsize)\n",
    "ax.set_xlabel('Images Seen', fontsize=fontsize)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim([10**5*n_gpus_train,10**(11.2)*n_gpus_train])\n",
    "ax.set_ylim([-0.3,0.17])\n",
    "ax.tick_params(axis='both', which='both', labelsize=fontsize, length=fontsize/2, width=1.5)\n",
    "ax.legend(['Fiducial', 'Fiducial Power-law', 'Sequential'], fontsize=fontsize, loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81945a94-87b8-4052-9c88-845363a3bf43",
   "metadata": {},
   "source": [
    "## Figure 6 <a id='figure_6'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc2744-17bd-4f15-bc70-44d5f1690ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the data\n",
    "save_metrics = np.load('figure_data/snpe_comparison_metrics.npy', allow_pickle=True).item()\n",
    "mean_metrics = save_metrics['mean_metrics']\n",
    "log_var_metrics = save_metrics['log_var_metrics']\n",
    "truth_hier = np.load('figure_data/truth_hier.npy')\n",
    "\n",
    "# Load up the encodings used to train the model to calculate the apt loss normalized to the \n",
    "# distribution used to train the NPE model.\n",
    "from paltax.TrainConfigs import train_config_npe_base\n",
    "from paltax.TrainConfigs import train_config_snpe_base\n",
    "config = train_config_npe_base.get_config()\n",
    "snpe_config = train_config_snpe_base.get_config()\n",
    "n_gpus_train = 4 #Number of gpus that were used in parallel when training the models.\n",
    "mu_prior = snpe_config.mu_prior\n",
    "prec_prior = snpe_config.prec_prior\n",
    "mu_prop_init = snpe_config.mu_prop_init\n",
    "prec_prop_init = snpe_config.prec_prop_init\n",
    "std_prop_init = jnp.power(jnp.diag(prec_prop_init), -0.5)\n",
    "prop_encoding = jax.vmap(input_pipeline.encode_normal)(\n",
    "        mu_prop_init, std_prop_init\n",
    ")\n",
    "steps = np.arange(1,501) * config.steps_per_epoch\n",
    "steps_snpe = np.arange(1,50) * config.steps_per_epoch\n",
    "\n",
    "# Use the mean, variance, and truths to build the loss for the plot.\n",
    "gaussian_loss_vmap = jax.jit(jax.vmap(train.gaussian_loss, in_axes=[0,None]))\n",
    "\n",
    "mean_fid_array = jnp.array(jax.tree_util.tree_leaves(mean_metrics['Fiducial']))\n",
    "log_var_fid_array = jnp.array(jax.tree_util.tree_leaves(log_var_metrics['Fiducial']))\n",
    "log_post_fid_all_array = []\n",
    "output = jnp.concatenate([mean_fid_array, log_var_fid_array], axis=-1)\n",
    "for mod_num in range(32):\n",
    "    log_post_model = []\n",
    "    for pi in range(11):\n",
    "        log_post_model += [gaussian_loss_vmap(\n",
    "            output[:,mod_num:mod_num+1,[pi,pi+11]], truth_hier[mod_num:mod_num+1,pi:pi+1]\n",
    "        )]\n",
    "    log_post_fid_all_array += [jnp.stack(log_post_model, axis=1)]\n",
    "log_post_fid_all_array = jnp.stack(log_post_fid_all_array, axis=0)\n",
    "\n",
    "# Repeat the same for the sequential loss.\n",
    "snpe_c_loss_vmap = jax.jit(jax.vmap(train.snpe_c_loss, in_axes=[0,None,None,None,None]))\n",
    "mean_seq_array = []\n",
    "log_seq_array = []\n",
    "log_post_all_array = []\n",
    "for mn, mod_num in [(f'Image {mod_num}', mod_num) for mod_num in range(30)]:\n",
    "    mean_seq_array += [jnp.array(jax.tree_util.tree_leaves(mean_metrics[mn]))[:,0]]\n",
    "    log_seq_array += [jnp.array(jax.tree_util.tree_leaves(log_var_metrics[mn]))[:,0]]\n",
    "    output = jnp.concatenate([mean_seq_array[-1], log_seq_array[-1]], axis=-1)\n",
    "    log_post_model = []\n",
    "    for pi in range(11):\n",
    "        log_post_model += [snpe_c_loss_vmap(\n",
    "            output[:,jnp.newaxis,[pi,pi+11]], truth_hier[mod_num:mod_num+1,pi:pi+1], prop_encoding[pi:pi+1], \n",
    "            mu_prior[pi:pi+1], prec_prior[pi:pi+1,pi:pi+1]\n",
    "        )]\n",
    "    log_post_all_array += [jnp.stack(log_post_model, axis=1)]\n",
    "  \n",
    "mean_seq_array = jnp.stack(mean_seq_array, axis=1)\n",
    "log_seq_array = jnp.stack(log_seq_array, axis=1)\n",
    "log_post_all_array = jnp.stack(log_post_all_array, axis=0)\n",
    "\n",
    "# Plot the loss comparison for desired parameters. By default plots theta_E, the parameter\n",
    "# used in Figure 6.\n",
    "fontsize = 20\n",
    "colors = ['#d95f02', '#1b9e77', 'grey']\n",
    "snpe_cut = 40\n",
    "filter_size = 5\n",
    "parameter_print_names = [r'$\\theta_\\mathrm{E}$', r'$\\gamma_\\mathrm{lens}$', r'$x_\\mathrm{lens}$',\n",
    "                         r'$y_\\mathrm{lens}$', r'$e_1$', r'$e_2$', r'$\\gamma_1$',\n",
    "                         r'$\\gamma_2$', r'$x_\\mathrm{source}$',\n",
    "                         r'$y_\\mathrm{source}$', r'$\\Sigma_\\mathrm{sub}$']\n",
    "for param_i in [0]:\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(9,8), sharey=True, gridspec_kw={'hspace': 0.02,'wspace':0.04},dpi=100)\n",
    "\n",
    "    npe_loss_array = np.mean(log_post_fid_all_array[:30,:,param_i], axis=0)\n",
    "    npe_loss_array = signal.medfilt(npe_loss_array, kernel_size=filter_size)\n",
    "    ax.plot(steps[:len(npe_loss_array)] * config.batch_size * n_gpus_train, npe_loss_array, '.-', c=colors[0], \n",
    "             lw=3, ms = 10, alpha=0.9)\n",
    "    snpe_loss_array = signal.medfilt(np.mean(log_post_all_array[:,:snpe_cut,param_i], axis=0), kernel_size=filter_size)\n",
    "    ax.plot(steps_snpe[:snpe_cut] * config.batch_size * n_gpus_train, snpe_loss_array, '.-', c=colors[1], lw=3, ms = 10, \n",
    "            alpha=0.9)\n",
    "\n",
    "    ax.set_ylabel(r'Mean Loss on ' + parameter_print_names[param_i], fontsize=fontsize)\n",
    "    ax.set_xlabel('Images Seen', fontsize=fontsize)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim([10**5*n_gpus_train,10**(7.9)*n_gpus_train])\n",
    "    # ax.set_ylim([-0.3,0.17])\n",
    "    ax.tick_params(axis='both', which='both', labelsize=fontsize, length=fontsize/2, width=1.5)\n",
    "    ax.legend(['Fiducial', 'Sequential'], fontsize=fontsize, loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c54d806-b8ba-450c-b5b1-a1069380e0d8",
   "metadata": {},
   "source": [
    "## Figure 7 <a id='figure_7'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad356d0-78dd-4fe7-8b67-f5e2f308202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_index = 5\n",
    "image_hier = np.load('figure_data/image_hier.npy')\n",
    "image_draws_list = np.load('figure_data/image_draws_list_4.npy')\n",
    "def create_grid(images, n_row_col):\n",
    "    placeholder = images[:n_row_col ** 2].reshape((n_row_col, n_row_col, *images.shape[1:]))\n",
    "    return np.vstack([np.hstack(image) for image in placeholder])\n",
    "    \n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,10), gridspec_kw={'hspace': 0.025,'wspace':0.02},dpi=100)\n",
    "box_colors = ['#bdd7e7', '#6baed6', '#2171b5']\n",
    "n_row_col = 4\n",
    "spine_width = 8\n",
    "fontsize = 20\n",
    "\n",
    "# I don't have the normalization for the mock image saved, so we'll need to reintroduce a reasonable standard deviation\n",
    "# to be able to use the same norm for all the images.\n",
    "image_mock = image_hier[mock_index] * np.mean(np.std(image_draws_list[0].reshape(image_draws_list[0].shape[0],-1), axis=1))\n",
    "\n",
    "im_norm = simple_norm(image_mock,stretch='asinh')\n",
    "axes[0,0].imshow(image_mock, norm=im_norm, cmap='plasma')\n",
    "axes[0,0].text(64, 14, 'Mock Observation', fontsize=fontsize, ha='center', color='white',\n",
    "               bbox=dict(boxstyle=\"round\",ec='grey',fc='grey', alpha=0.8))\n",
    "axes[0,1].imshow(create_grid(image_draws_list[0], n_row_col), norm=im_norm, cmap='plasma')\n",
    "axes[0,1].text(64 * n_row_col, 14 * n_row_col, r'$p(\\theta|\\Omega_0)$', fontsize=fontsize, ha='center', \n",
    "               color='white', bbox=dict(boxstyle=\"round\",ec='grey',fc='grey', alpha=0.8))\n",
    "axes[1,0].imshow(create_grid(image_draws_list[1], n_row_col), norm=im_norm, cmap='plasma')\n",
    "axes[1,0].text(64 * n_row_col, 14 * n_row_col, r'$p(\\theta|\\Omega_1)$', fontsize=fontsize, ha='center', \n",
    "               color='white', bbox=dict(boxstyle=\"round\",ec='grey',fc='grey', alpha=0.8))\n",
    "axes[1,1].imshow(create_grid(image_draws_list[2], n_row_col), norm=im_norm, cmap='plasma')\n",
    "axes[1,1].text(64 * n_row_col, 14 * n_row_col, r'$p(\\theta|\\Omega_3)$', fontsize=fontsize, ha='center', \n",
    "               color='white', bbox=dict(boxstyle=\"round\",ec='grey',fc='grey', alpha=0.8))\n",
    "for ax in axes.flatten():\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "for i in range(3):\n",
    "    for spine in axes.flatten()[i+1].spines.values():\n",
    "        spine.set_edgecolor(box_colors[i])\n",
    "        spine.set_linewidth(spine_width)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b573cf8a-2bdf-4a35-a71a-8d56304f61f3",
   "metadata": {},
   "source": [
    "## Figure 8 <a id='figure_8'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1f4e87-fd90-4ceb-872e-6417d044448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_param_print=[r'$\\Sigma_\\mathrm{sub,pop}$' + r' $[\\mathrm{kpc}^{-2}]$',\n",
    "                    r'$\\Sigma_\\mathrm{sub,pop,\\sigma}$' + r' $[\\mathrm{kpc}^{-2}]$']\n",
    "fontsize = 20\n",
    "figsize = (12,12)\n",
    "\n",
    "truth_color = 'k'\n",
    "truths = np.array([1.5e-3, 2e-4])\n",
    "burnin = 1000\n",
    "\n",
    "# Plot the corner plots for the fiducial model.\n",
    "model_name = 'fiducial_1950000'\n",
    "n_lenses_list = [10, 30]\n",
    "colors = ['#d95f02']\n",
    "for n_lenses in n_lenses_list:\n",
    "    \n",
    "    chains_path = f'figure_data/m_{model_name}_{n_lenses}_lenses_loose_chains.npy'\n",
    "    print(chains_path)\n",
    "\n",
    "    chain =  np.load(chains_path)[3,:,burnin:].reshape((-1,2))\n",
    "    # Renormalize\n",
    "    chain[:,0] *= 1.1e-3\n",
    "    chain[:,0] += 2e-3\n",
    "    chain[:,1] *= 1.1e-3\n",
    "    \n",
    "    hist_kwargs = {'density':True,'color':colors[0],'lw':3}\n",
    "    plot_range = [(0.0, 4e-3),(0,0.005)]\n",
    "    \n",
    "    f = corner.corner(chain, range=plot_range, labels=corner_param_print,bins=20, show_titles=True, plot_datapoints=False,\n",
    "                      label_kwargs=dict(fontsize=fontsize),levels=[0.68,0.95],\n",
    "                      color=colors[0],fill_contours=True,hist_kwargs=hist_kwargs,title_fmt='.4f',truths=truths,\n",
    "                      truth_color=truth_color,max_n_ticks=3)\n",
    "    \n",
    "    # Do some whacky stuff to deal with corner\n",
    "    f.set_figheight(figsize[0])\n",
    "    f.set_figwidth(figsize[1])\n",
    "    for i in range(len(truths)):\n",
    "        for j in range(len(truths)):\n",
    "            corn_axis = f.axes[i*(len(truths))+j]\n",
    "            corn_axis.title.set_fontsize(fontsize)\n",
    "            if j == 0:\n",
    "                if i > 0:\n",
    "                    corn_axis.tick_params(axis='y', labelsize=fontsize,labelrotation=75)\n",
    "                    corn_axis.set_ylabel(corner_param_print[i],fontsize=fontsize * 1.5, labelpad=10.0)\n",
    "            if i == len(truths)-1:\n",
    "                corn_axis.tick_params(axis='x', labelsize=fontsize,labelrotation=15)\n",
    "                corn_axis.set_xlabel(corner_param_print[j],fontsize=fontsize * 1.5, labelpad=10.0)\n",
    "    plt.show()\n",
    "\n",
    "# Plot the corner plots for the sequential model.\n",
    "colors = ['#1b9e77']\n",
    "model_name = 'sequential_117000'\n",
    "for n_lenses in n_lenses_list:\n",
    "    \n",
    "    chains_path = f'figure_data/m_{model_name}_{n_lenses}_lenses_loose_chains.npy'\n",
    "    print(chains_path)\n",
    "\n",
    "    chain =  np.load(chains_path)[0,:,burnin:].reshape((-1,2))\n",
    "    # Renormalize\n",
    "    chain[:,0] *= 1.1e-3\n",
    "    chain[:,0] += 2e-3\n",
    "    chain[:,1] *= 1.1e-3\n",
    "    \n",
    "    hist_kwargs = {'density':True,'color':colors[0],'lw':3}\n",
    "    plot_range = [(0.0, 4e-3),(0,0.005)]\n",
    "    \n",
    "    f = corner.corner(chain, range=plot_range, labels=corner_param_print,bins=20, show_titles=True, plot_datapoints=False,\n",
    "                      label_kwargs=dict(fontsize=fontsize),levels=[0.68,0.95],\n",
    "                      color=colors[0],fill_contours=True,hist_kwargs=hist_kwargs,title_fmt='.4f',truths=truths,\n",
    "                      truth_color=truth_color,max_n_ticks=3)\n",
    "    \n",
    "    # Do some whacky stuff to deal with corner\n",
    "    f.set_figheight(figsize[0])\n",
    "    f.set_figwidth(figsize[1])\n",
    "    for i in range(len(truths)):\n",
    "        for j in range(len(truths)):\n",
    "            corn_axis = f.axes[i*(len(truths))+j]\n",
    "            corn_axis.title.set_fontsize(fontsize)\n",
    "            if j == 0:\n",
    "                if i > 0:\n",
    "                    corn_axis.tick_params(axis='y', labelsize=fontsize,labelrotation=75)\n",
    "                    corn_axis.set_ylabel(corner_param_print[i],fontsize=fontsize * 1.5, labelpad=10.0)\n",
    "            if i == len(truths)-1:\n",
    "                corn_axis.tick_params(axis='x', labelsize=fontsize,labelrotation=15)\n",
    "                corn_axis.set_xlabel(corner_param_print[j],fontsize=fontsize * 1.5, labelpad=10.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0fdd27-bd2d-482e-8e49-eb868bf4b60f",
   "metadata": {},
   "source": [
    "## Figure 9 <a id='figure_9'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0908777e-5723-4520-b645-1356fb3e8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "npe_n_lenses_list = [5,10,15,20,25,30,40,50,60,70,80,90,100,110,120]\n",
    "snpe_n_lenses_list = [5,10,15,20,25,30]\n",
    "n_permutation = 10\n",
    "\n",
    "# Extract the fits for permutations of all the number of lenses.\n",
    "def extract_pop_std(n_lenses_list, n_permutation, model_type, fit_type, burnin):\n",
    "\n",
    "    pop_std = np.zeros((len(n_lenses_list), n_permutation))\n",
    "\n",
    "    for ni, n_lenses in enumerate(n_lenses_list):\n",
    "\n",
    "        chains_path = f'figure_data/m_{model_type}_{n_lenses}_lenses_{fit_type}_chains.npy'\n",
    "        chain = np.load(chains_path)[:,:,burnin:]\n",
    "        chain = chain.reshape((chain.shape[0],-1,2))\n",
    "\n",
    "        # Renormalize\n",
    "        chain[:,:,0] *= 1.1e-3\n",
    "        chain[:,:,0] += 2e-3\n",
    "        chain[:,:,1] *= 1.1e-3\n",
    "\n",
    "        pop_std[ni] = np.std(chain[:,:,0],axis=1)\n",
    "\n",
    "    return pop_std\n",
    "\n",
    "# Load the fits where the scatter is fixed for the line plot.\n",
    "burnin = 1000\n",
    "fit_npe_pop_std = extract_pop_std(npe_n_lenses_list, n_permutation, 'fiducial_1950000', 'tight', burnin)\n",
    "fit_snpe_pop_std = extract_pop_std(snpe_n_lenses_list, n_permutation, 'sequential_117000', 'tight', burnin)\n",
    "npe_pop_std = extract_pop_std(npe_n_lenses_list, n_permutation, 'fiducial_1950000', 'loose', burnin)\n",
    "snpe_pop_std = extract_pop_std(snpe_n_lenses_list, n_permutation, 'sequential_117000', 'loose', burnin)\n",
    "\n",
    "# Do a fit to each of the samples.\n",
    "npe_lin_fits = np.zeros((npe_pop_std.shape[1], 2))\n",
    "snpe_lin_fits = np.zeros((snpe_pop_std.shape[1], 2))\n",
    "log_npe_n_lenses = np.log10(npe_n_lenses_list)\n",
    "log_snpe_n_lenses = np.log10(snpe_n_lenses_list)\n",
    "\n",
    "for i in range(npe_pop_std.shape[1]):\n",
    "    npe_lin_fit = stats.linregress(log_npe_n_lenses[3:], np.log10(fit_npe_pop_std[3:,i]))\n",
    "    snpe_lin_fit = stats.linregress(log_snpe_n_lenses[1:], np.log10(fit_snpe_pop_std[1:,i]))\n",
    "    npe_lin_fits[i,0], npe_lin_fits[i,1] = npe_lin_fit[0], npe_lin_fit[1]\n",
    "    snpe_lin_fits[i,0], snpe_lin_fits[i,1] = snpe_lin_fit[0], snpe_lin_fit[1]\n",
    "\n",
    "# Plot the constraint as a function of number of lenses.\n",
    "fontsize=15\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,7), dpi=150)\n",
    "\n",
    "colors = ['#d95f02', '#1b9e77', 'grey']\n",
    "\n",
    "# Calculate the quantiles for the constraining power and plot them with the median value.\n",
    "npe_quantiles = np.stack(\n",
    "    [np.median(npe_pop_std, axis=1)-np.quantile(npe_pop_std, 0.16, axis=1),\n",
    "     np.quantile(npe_pop_std, 0.84, axis=1) - np.median(npe_pop_std, axis=1)],\n",
    "    axis=0)\n",
    "snpe_quantiles = np.stack(\n",
    "    [np.median(snpe_pop_std, axis=1)-np.quantile(snpe_pop_std, 0.16, axis=1),\n",
    "     np.quantile(snpe_pop_std, 0.84, axis=1) - np.median(snpe_pop_std, axis=1)],\n",
    "    axis=0)\n",
    "ax.errorbar(npe_n_lenses_list, np.median(npe_pop_std, axis=1), yerr=npe_quantiles, \n",
    "            fmt='.', c=colors[0], ms = 15, label='Fiducial')\n",
    "ax.errorbar(snpe_n_lenses_list, np.median(snpe_pop_std, axis=1), yerr=snpe_quantiles, \n",
    "            fmt='.', c=colors[1], ms = 15, label='Sequential')\n",
    "\n",
    "# large_n_alpha = 0.3\n",
    "# ax.errorbar(npe_n_lenses_list, np.median(fit_npe_pop_std, axis=1),\n",
    "#             fmt='.', c=colors[0], ms = 15, alpha=large_n_alpha)\n",
    "# ax.errorbar(snpe_n_lenses_list, np.median(fit_snpe_pop_std, axis=1),\n",
    "#             fmt='.', c=colors[1], ms = 15, alpha=large_n_alpha)\n",
    "\n",
    "# Plot the large N power law.\n",
    "mean_npe_lin_fits = np.mean(npe_lin_fits, axis=0)\n",
    "min_npe_lin_fits = np.quantile(npe_lin_fits, 0.16, axis=0)\n",
    "max_npe_lin_fits = np.quantile(npe_lin_fits, 0.84, axis=0)\n",
    "mean_snpe_lin_fits = np.mean(snpe_lin_fits, axis=0)\n",
    "min_snpe_lin_fits = np.quantile(snpe_lin_fits, 0.16, axis=0)\n",
    "max_snpe_lin_fits = np.quantile(snpe_lin_fits, 0.84, axis=0)\n",
    "\n",
    "npe_p_law_steps = np.linspace(np.log10(3), np.log10(280), 100)\n",
    "npe_p_law = mean_npe_lin_fits[0]*npe_p_law_steps + mean_npe_lin_fits[1]\n",
    "ax.plot(10**(npe_p_law_steps), 10**npe_p_law, '-.', c=colors[0], lw=3, label='Fiducial: Large $N_\\mathrm{lens}$ Scaling')\n",
    "\n",
    "snpe_p_law_steps = np.linspace(np.log10(3), np.log10(55), 100)\n",
    "snpe_p_law = mean_snpe_lin_fits[0]*snpe_p_law_steps + mean_snpe_lin_fits[1]\n",
    "ax.plot(10**(snpe_p_law_steps), 10**snpe_p_law, '--', c=colors[1], lw=3, label='Sequential: Large $N_\\mathrm{lens}$ Scaling')\n",
    "\n",
    "# Describe the power law lines\n",
    "ax.text(10**(npe_p_law_steps[5]), 10**(npe_p_law[5]), r'$\\propto N^{-0.5}$',fontsize=fontsize, rotation=-25, \n",
    "        horizontalalignment='center', verticalalignment='bottom', rotation_mode='anchor')\n",
    "ax.text(10**(snpe_p_law_steps[8]), 10**(snpe_p_law[8]), r'$\\propto N^{-0.5}$',fontsize=fontsize, rotation=-25,\n",
    "        horizontalalignment='center', verticalalignment='bottom', rotation_mode='anchor')\n",
    "\n",
    "# Label the gap between the two power laws and the regions of interes.\n",
    "percent_measurement = 0.2\n",
    "ax.axhspan(1.4e-3*percent_measurement,1.6e-3*percent_measurement, color=colors[2], alpha=0.3)\n",
    "ax.text(3.0,1.5e-3*percent_measurement*0.965, r'$5\\sigma$ Detection', color='white', fontsize=fontsize,\n",
    "        bbox=dict(boxstyle=\"round\",ec='#969696',fc='#969696'))\n",
    "\n",
    "c_vert = 1.5e-4\n",
    "x_snpe = 10**((np.log10(c_vert)-mean_snpe_lin_fits[1])/mean_snpe_lin_fits[0])\n",
    "x_npe = 10**((np.log10(c_vert)-mean_npe_lin_fits[1])/mean_npe_lin_fits[0])\n",
    "ax.annotate(text='', xy=(x_npe,c_vert), xytext=(x_snpe,c_vert), arrowprops=dict(arrowstyle='<->', lw=2))\n",
    "ax.text(95,c_vert + 0.1e-4,f'~{x_npe/x_snpe:.0f}x',fontsize=fontsize)\n",
    "\n",
    "percent_measurement = 0.1\n",
    "ax.axhspan(1.4e-3*percent_measurement,1.6e-3*percent_measurement, color=colors[2], alpha=0.3)\n",
    "ax.text(3.0,1.455e-4, r'$10\\%$ Measurement', color='white', fontsize=fontsize,\n",
    "        bbox=dict(boxstyle=\"round\",ec='#969696',fc='#969696'))\n",
    "\n",
    "# Format the plot.\n",
    "ax.set_ylabel('Uncertainty on ' + r'$\\Sigma_\\mathrm{sub,pop}$',fontsize=fontsize)\n",
    "ax.set_xlabel('Number of Analyzed Lenses', fontsize=fontsize)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.tick_params(axis='both', which='both', labelsize=fontsize, length=fontsize/2, width=1.5)\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "order = [2,3,0,1]\n",
    "ax.legend([handles[idx] for idx in order],[labels[idx] for idx in order], fontsize=fontsize, loc='upper right')\n",
    "ax.set_ylim([1.2e-4,3e-3])\n",
    "ax.set_xlim([2.5,340])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
